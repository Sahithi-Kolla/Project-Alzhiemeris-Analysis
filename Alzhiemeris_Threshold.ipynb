{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Required Packages for the Project RUN ONLY ONCE\n",
    "# %pip install matplotlib\n",
    "# %pip install nilearn\n",
    "# %pip install openpyxl\n",
    "# %pip install Path\n",
    "# %pip install seaborn\n",
    "# %pip install nltools\n",
    "# %pip install scipy\n",
    "# %pip install scikit-image\n",
    "# %pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# from skimage import filters\n",
    "# import json\n",
    "# import nibabel as nib\n",
    "# from nilearn.plotting import plot_img\n",
    "\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nilearn.image import load_img, index_img\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import networkx as nx\n",
    "import matplotlib as mt\n",
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectData:\n",
    "    \n",
    "    def __init__(self, datasetPath, componentsPath):\n",
    "        self.componentFileName = \"adni_aa__sub01_component_ica_s1_.nii\"\n",
    "        self.timeCourseFileName = \"adni_aa__sub01_timecourses_ica_s1_.nii\"\n",
    "        self.FNCmatFile = \"adni_aa__postprocess_results.mat\"\n",
    "        self.component_key = \"fnc_corrs_all\"\n",
    "        self.graphMetricNames = [\n",
    "                \"Global efficiency\", \n",
    "                \"Characteristic path length\", \n",
    "                \"Clustering coefficient\",\n",
    "                # \"\"\n",
    "            ]\n",
    "        \n",
    "        self.subjectsData = self.readFileofCSV(datasetPath) \n",
    "        self.componentData = self.readFileofCSV(componentsPath)\n",
    "\n",
    "        self.modifySubjectsPath()\n",
    "\n",
    "        self.domainList = self.componentData[\"icn_domain\"]\n",
    "        self.indexList = self.componentData[\"icn_index\"]\n",
    "\n",
    "    def modifySubjectsPath(self):\n",
    "        for i in range(2404):\n",
    "            self.subjectsData.at[i,\"fc_dir\"] = self.subjectsData.iloc[i][\"fc_dir\"].replace(\"FC\",\"GIGICA\")\n",
    "\n",
    "    def readFileofCSV(self,path):\n",
    "        fileData = pd.read_csv(path)\n",
    "        return fileData\n",
    "    \n",
    "    def getDatasetPaths(self,subjectName):\n",
    "        ans = list()\n",
    "        for i in range(2404):\n",
    "            if self.subjectsData.at[i,\"ResearchGroup\"] == subjectName:\n",
    "                ans.append(self.subjectsData.at[i,\"fc_dir\"])\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelCounts(SubjectData):\n",
    "    \" \\\n",
    "        datasetPath : 4D images path \\\n",
    "        componentsPath: indexes path \\\n",
    "        subjectList: List of subjects to calculate ex: AD, CN, ....  \\\n",
    "    \"\n",
    "    def __init__(self,datasetPath, componentsPath, subjectList):\n",
    "        super().__init__(datasetPath,componentsPath)\n",
    "        self.subjectsToCalculate = subjectList\n",
    "\n",
    "        self.voxelCountMap = dict()\n",
    "        self.prepareVoxelCountMap()\n",
    "\n",
    "    def prepareVoxelCountMap(self):\n",
    "        \" \\\n",
    "            iterate over the list of Subjects like AD, CN, ....     \\\n",
    "        \"\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            self.voxelCountMap[subjectName]=dict()\n",
    "            self.voxelCountMap[subjectName][\"paths\"] = self.getDatasetPaths(subjectName)\n",
    "            self.voxelCountMap[subjectName][\"indexes\"] = dict()\n",
    "            for i in self.indexList:\n",
    "                self.voxelCountMap[subjectName][\"indexes\"][i]=list()\n",
    "\n",
    "    def calculateVoxelCount(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            for path in self.voxelCountMap[subjectName][\"paths\"]:\n",
    "                spacialMapName = path + self.componentFileName\n",
    "                spacialMap = load_img(spacialMapName)\n",
    "                for index in self.voxelCountMap[subjectName][\"indexes\"]:\n",
    "                    actualIndex=index-1\n",
    "                    componentImg = index_img(spacialMap, actualIndex)\n",
    "                    componentImgData = componentImg.get_fdata()\n",
    "                    component_threshold = 3*np.std(componentImgData)\n",
    "                    component_voxelCount = np.count_nonzero(componentImgData > component_threshold)\n",
    "                    self.voxelCountMap[subjectName][\"indexes\"][index].append(component_voxelCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_Threshold = VoxelCounts('ADNI_demos.txt', 'NM_icns_info.csv', [\"AD\",\"CN\"])\n",
    "AD_Threshold.calculateVoxelCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMetrics(SubjectData):\n",
    "\n",
    "    \" \\\n",
    "        datasetPath : 4D images path \\\n",
    "        componentsPath: indexes path \\\n",
    "        subjectList: List of subjects to calculate ex: AD, CN, ....  \\\n",
    "    \"\n",
    "    \n",
    "    def __init__(self,datasetPath, componentsPath, subjectList):\n",
    "        super().__init__(datasetPath,componentsPath)\n",
    "        self.subjectsToCalculate = subjectList\n",
    "\n",
    "        self.graphMetricMap = dict()\n",
    "        self.prepareGraphMetricMap()\n",
    "\n",
    "    def prepareGraphMetricMap(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            self.graphMetricMap[subjectName]=dict()\n",
    "            self.graphMetricMap[subjectName][\"paths\"] = self.getDatasetPaths(subjectName)\n",
    "            for graphMetic in self.graphMetricNames:\n",
    "                self.graphMetricMap[subjectName][graphMetic]=list()\n",
    "\n",
    "    def loadMatFile(self,filePath):\n",
    "        componentDict = scipy.io.loadmat(filePath+self.FNCmatFile)\n",
    "        return componentDict[self.component_key]\n",
    "\n",
    "    def prepareFNCMatrix(self,componentData):\n",
    "        selected_component = np.zeros((53,53), dtype=np.float64).reshape(53,53)\n",
    "        for i in range(53):\n",
    "            for j in range(i+1, 53):\n",
    "                # if componentData[self.indexList[i]-1][self.indexList[j]-1] >=0 : \n",
    "                selected_component[i][j]=componentData[self.indexList[i]-1][self.indexList[j]-1]\n",
    "        selected_component += selected_component.T\n",
    "\n",
    "        # Finding correlation matrix\n",
    "        corrs = pd.DataFrame(selected_component)\n",
    "        correlation_matrix = corrs.corr()\n",
    "        correlation_numpy_array = correlation_matrix.to_numpy(dtype=np.float64)\n",
    "\n",
    "        # Finding Thresholded correlation matrix\n",
    "        row,column = correlation_numpy_array.shape\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                if i!=j and correlation_numpy_array[i][j]<0:\n",
    "                    correlation_numpy_array[i][j]=0\n",
    "\n",
    "        input_matrix = nx.from_numpy_array(correlation_numpy_array)\n",
    "        return input_matrix\n",
    "\n",
    "    def calculateGraphMetrics(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            for path in self.graphMetricMap[subjectName][\"paths\"]:\n",
    "                fncMatrix = self.prepareFNCMatrix(self.loadMatFile(path))\n",
    "                for graphMetric in self.graphMetricNames:\n",
    "                    if graphMetric == \"Global efficiency\":\n",
    "                        globalEfficieny = nx.global_efficiency(fncMatrix)\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(globalEfficieny)\n",
    "\n",
    "                    elif graphMetric == \"Characteristic path length\":\n",
    "                        characteristicPathLength = nx.average_shortest_path_length(fncMatrix, weight='weight')\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(characteristicPathLength)\n",
    "\n",
    "                    elif graphMetric == \"Clustering coefficient\":\n",
    "                        clusterCofficient = nx.clustering(fncMatrix, weight='weight')\n",
    "                        clusterCofficient_network = 0\n",
    "                        for i in clusterCofficient:\n",
    "                            clusterCofficient_network += clusterCofficient[i]\n",
    "                        clusterCofficient_network /= 53\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(clusterCofficient_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_GraphMetric = GraphMetrics('ADNI_demos.txt', 'NM_icns_info.csv', [\"AD\",\"CN\"])\n",
    "AD_GraphMetric.calculateGraphMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table.columns = column_names\n",
    "# table.index = AD_GraphMetric.graphMetricNames\n",
    "\n",
    "# table\n",
    "\n",
    "# correlation = table[\"Characteristic path length\"].corr(table[69])\n",
    "# sns.regplot(x=table[\"Global efficiency\"], y=table[AD_Threshold.domainList[0]])\n",
    "# sns.regplot(x=table[\"Global efficiency\"], y=table[AD_Threshold.domainList[6]])\n",
    "\n",
    "GraphMetrics_Names = AD_GraphMetric.graphMetricNames\n",
    "ans1 = list()\n",
    "\n",
    "for subjectName in AD_GraphMetric.subjectsToCalculate:\n",
    "\n",
    "    table = pd.DataFrame()\n",
    "    for i in range(len(AD_Threshold.indexList)):\n",
    "        table[AD_Threshold.domainList[i]+'('+str(AD_Threshold.indexList[i])+')'] = list()\n",
    "\n",
    "    for i in GraphMetrics_Names:\n",
    "        indexList = AD_Threshold.indexList\n",
    "        corr_list = list()\n",
    "\n",
    "        xlist = AD_GraphMetric.graphMetricMap[subjectName][i]\n",
    "        xmean = np.mean(xlist)\n",
    "        xval = xlist - xmean\n",
    "        xsqu = np.sqrt(np.sum(np.square(xval)))\n",
    "\n",
    "        for j in range(len(indexList)):\n",
    "\n",
    "            ylist = AD_Threshold.voxelCountMap[subjectName][\"indexes\"][AD_Threshold.indexList[j]]\n",
    "            ymean = np.mean(ylist)\n",
    "            yval = ylist - ymean\n",
    "            ysqu = np.sqrt(np.sum(np.square(yval)))\n",
    "\n",
    "            num = 0\n",
    "            for k in range(len(yval)):\n",
    "                num += (xval[k]*yval[k])\n",
    "\n",
    "            den = (xsqu * ysqu)\n",
    "            ans = num/den\n",
    "            corr_list.append(ans)\n",
    "\n",
    "        table.loc[len(table.index)] = corr_list\n",
    "    table.index = AD_GraphMetric.graphMetricNames\n",
    "    ans1.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ans1\n",
    "\n",
    "temp[0].to_csv('./Alzhiemeris.csv')\n",
    "temp[1].to_csv('./Controls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans1[1].to_csv('./Controls.csv')\n",
    "\n",
    "columns = ans1[1].columns.values\n",
    "\n",
    "rows = ans1[1].index.values\n",
    "\n",
    "# print(ans1[0][rows[0]][columns[0]] - ans1[1][rows[0]][columns[0]])\n",
    "\n",
    "for i in rows:\n",
    "    for j in columns:\n",
    "        ans1[1].at[i,j] -= ans1[0].at[i,j]\n",
    "\n",
    "ans1[1].to_csv('./difference.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
