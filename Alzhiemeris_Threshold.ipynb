{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Required Packages for the Project RUN ONLY ONCE\n",
    "# %pip install matplotlib\n",
    "# %pip install nilearn\n",
    "# %pip install openpyxl\n",
    "# %pip install Path\n",
    "# %pip install seaborn\n",
    "# %pip install nltools\n",
    "# %pip install scipy\n",
    "# %pip install scikit-image\n",
    "# %pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/skolla3/AlzhiemerisProject/env/lib64/python3.6/site-packages/nilearn/__init__.py:69: FutureWarning: Python 3.6 support is deprecated and will be removed in release 0.10 of Nilearn. Consider switching to Python 3.8 or 3.9.\n",
      "  _python_deprecation_warnings()\n"
     ]
    }
   ],
   "source": [
    "# import copy\n",
    "# from skimage import filters\n",
    "# import json\n",
    "# import nibabel as nib\n",
    "# from nilearn.plotting import plot_img\n",
    "\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nilearn.image import load_img, index_img\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import networkx as nx\n",
    "import matplotlib as mt\n",
    "import scipy as sc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectData:\n",
    "    \n",
    "    def __init__(self, datasetPath, componentsPath):\n",
    "        self.componentFileName = \"adni_aa__sub01_component_ica_s1_.nii\"\n",
    "        self.timeCourseFileName = \"adni_aa__sub01_timecourses_ica_s1_.nii\"\n",
    "        self.FNCmatFile = \"adni_aa__postprocess_results.mat\"\n",
    "        self.component_key = \"fnc_corrs_all\"\n",
    "        self.graphMetricNames = [\n",
    "                \"Global efficiency\", \n",
    "                \"Characteristic path length\", \n",
    "                \"Clustering coefficient\",\n",
    "                # \"\"\n",
    "            ]\n",
    "        \n",
    "        self.subjectsData = self.readFileofCSV(datasetPath) \n",
    "        self.componentData = self.readFileofCSV(componentsPath)\n",
    "\n",
    "        self.modifySubjectsPath()\n",
    "\n",
    "        self.domainList = self.componentData[\"icn_domain\"]\n",
    "        self.indexList = self.componentData[\"icn_index\"]\n",
    "\n",
    "    def modifySubjectsPath(self):\n",
    "        for i in range(2404):\n",
    "            self.subjectsData.at[i,\"fc_dir\"] = self.subjectsData.iloc[i][\"fc_dir\"].replace(\"FC\",\"GIGICA\")\n",
    "\n",
    "    def readFileofCSV(self,path):\n",
    "        fileData = pd.read_csv(path)\n",
    "        return fileData\n",
    "    \n",
    "    def getDatasetPaths(self,subjectName):\n",
    "        ans = list()\n",
    "        for i in range(2404):\n",
    "            if self.subjectsData.at[i,\"ResearchGroup\"] == subjectName:\n",
    "                ans.append(self.subjectsData.at[i,\"fc_dir\"])\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelCounts(SubjectData):\n",
    "    \" \\\n",
    "        datasetPath : 4D images path \\\n",
    "        componentsPath: indexes path \\\n",
    "        subjectList: List of subjects to calculate ex: AD, CN, ....  \\\n",
    "    \"\n",
    "    def __init__(self,datasetPath, componentsPath, subjectList):\n",
    "        super().__init__(datasetPath,componentsPath)\n",
    "        self.subjectsToCalculate = subjectList\n",
    "\n",
    "        self.voxelCountMap = dict()\n",
    "        self.prepareVoxelCountMap()\n",
    "\n",
    "    def prepareVoxelCountMap(self):\n",
    "        \" \\\n",
    "            iterate over the list of Subjects like AD, CN, ....     \\\n",
    "        \"\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            self.voxelCountMap[subjectName]=dict()\n",
    "            self.voxelCountMap[subjectName][\"paths\"] = self.getDatasetPaths(subjectName)\n",
    "            self.voxelCountMap[subjectName][\"indexes\"] = dict()\n",
    "            for i in self.indexList:\n",
    "                self.voxelCountMap[subjectName][\"indexes\"][i]=list()\n",
    "\n",
    "    def calculateVoxelCount(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            for path in self.voxelCountMap[subjectName][\"paths\"]:\n",
    "                spacialMapName = path + self.componentFileName\n",
    "                spacialMap = load_img(spacialMapName)\n",
    "                for index in self.voxelCountMap[subjectName][\"indexes\"]:\n",
    "                    actualIndex=index-1\n",
    "                    componentImg = index_img(spacialMap, actualIndex)\n",
    "                    componentImgData = componentImg.get_fdata()\n",
    "                    component_threshold = 3*np.std(componentImgData)\n",
    "                    component_voxelCount = np.count_nonzero(componentImgData > component_threshold)\n",
    "                    self.voxelCountMap[subjectName][\"indexes\"][index].append(component_voxelCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AD_Threshold = VoxelCounts('ADNI_demos.txt', 'NM_icns_info.csv', [\"AD\",\"CN\"])\n",
    "AD_Threshold.calculateVoxelCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMetrics(SubjectData):\n",
    "\n",
    "    \" \\\n",
    "        datasetPath : 4D images path \\\n",
    "        componentsPath: indexes path \\\n",
    "        subjectList: List of subjects to calculate ex: AD, CN, ....  \\\n",
    "    \"\n",
    "\n",
    "    def __init__(self,datasetPath, componentsPath, subjectList):\n",
    "        super().__init__(datasetPath,componentsPath)\n",
    "        self.subjectsToCalculate = subjectList\n",
    "\n",
    "        self.graphMetricMap = dict()\n",
    "        self.prepareGraphMetricMap()\n",
    "\n",
    "    def prepareGraphMetricMap(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            self.graphMetricMap[subjectName]=dict()\n",
    "            self.graphMetricMap[subjectName][\"paths\"] = self.getDatasetPaths(subjectName)\n",
    "            for graphMetic in self.graphMetricNames:\n",
    "                self.graphMetricMap[subjectName][graphMetic]=list()\n",
    "\n",
    "    def loadMatFile(self,filePath):\n",
    "        componentDict = scipy.io.loadmat(filePath+self.FNCmatFile)\n",
    "        return componentDict[self.component_key]\n",
    "\n",
    "    def prepareFNCMatrix(self,componentData):\n",
    "        selected_component = np.zeros((53,53), dtype=np.float64).reshape(53,53)\n",
    "        for i in range(53):\n",
    "            for j in range(i+1, 53):\n",
    "                # if componentData[self.indexList[i]-1][self.indexList[j]-1] >=0 : \n",
    "                selected_component[i][j]=componentData[self.indexList[i]-1][self.indexList[j]-1]\n",
    "        selected_component += selected_component.T\n",
    "\n",
    "        # Finding correlation matrix\n",
    "        corrs = pd.DataFrame(selected_component)\n",
    "        correlation_matrix = corrs.corr()\n",
    "        correlation_numpy_array = correlation_matrix.to_numpy(dtype=np.float64)\n",
    "\n",
    "        # Finding Thresholded correlation matrix\n",
    "        row,column = correlation_numpy_array.shape\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                if i!=j and correlation_numpy_array[i][j]<0:\n",
    "                    correlation_numpy_array[i][j]=0\n",
    "\n",
    "        input_matrix = nx.from_numpy_array(correlation_numpy_array)\n",
    "        return input_matrix\n",
    "\n",
    "    def calculateGraphMetrics(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            for path in self.graphMetricMap[subjectName][\"paths\"]:\n",
    "                fncMatrix = self.prepareFNCMatrix(self.loadMatFile(path))\n",
    "                for graphMetric in self.graphMetricNames:\n",
    "                    if graphMetric == \"Global efficiency\":\n",
    "                        globalEfficieny = nx.global_efficiency(fncMatrix)\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(globalEfficieny)\n",
    "\n",
    "                    elif graphMetric == \"Characteristic path length\":\n",
    "                        characteristicPathLength = nx.average_shortest_path_length(fncMatrix, weight='weight')\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(characteristicPathLength)\n",
    "\n",
    "                    elif graphMetric == \"Clustering coefficient\":\n",
    "                        clusterCofficient = nx.clustering(fncMatrix, weight='weight')\n",
    "                        clusterCofficient_network = 0\n",
    "                        for i in clusterCofficient:\n",
    "                            clusterCofficient_network += clusterCofficient[i]\n",
    "                        clusterCofficient_network /= 53\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(clusterCofficient_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AD_GraphMetric = GraphMetrics('ADNI_demos.txt', 'NM_icns_info.csv', [\"AD\",\"CN\"])\n",
    "AD_GraphMetric.calculateGraphMetrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphMetrics_Names = AD_GraphMetric.graphMetricNames\n",
    "ans1 = list()\n",
    "\n",
    "for subjectName in AD_GraphMetric.subjectsToCalculate:\n",
    "\n",
    "    table = pd.DataFrame()\n",
    "    for i in range(len(AD_Threshold.indexList)):\n",
    "        table[AD_Threshold.domainList[i]+'('+str(AD_Threshold.indexList[i])+')'] = list()\n",
    "\n",
    "    for i in GraphMetrics_Names:\n",
    "        indexList = AD_Threshold.indexList\n",
    "        corr_list = list()\n",
    "\n",
    "        xlist = AD_GraphMetric.graphMetricMap[subjectName][i]\n",
    "        xmean = np.mean(xlist)\n",
    "        xval = xlist - xmean\n",
    "        xsqu = np.sqrt(np.sum(np.square(xval)))\n",
    "\n",
    "        for j in range(len(indexList)):\n",
    "\n",
    "            ylist = AD_Threshold.voxelCountMap[subjectName][\"indexes\"][AD_Threshold.indexList[j]]\n",
    "            ymean = np.mean(ylist)\n",
    "            yval = ylist - ymean\n",
    "            ysqu = np.sqrt(np.sum(np.square(yval)))\n",
    "\n",
    "            num = 0\n",
    "            for k in range(len(yval)):\n",
    "                num += (xval[k]*yval[k])\n",
    "\n",
    "            den = (xsqu * ysqu)\n",
    "            ans = num/den\n",
    "            corr_list.append(ans)\n",
    "\n",
    "        table.loc[len(table.index)] = corr_list\n",
    "    table.index = AD_GraphMetric.graphMetricNames\n",
    "    ans1.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ans1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symvalue = 0.5\n",
    "fileNames = ['Alzhiemeris', 'Controls']\n",
    "for i in range(len(fileNames)):\n",
    "        temp[i].to_csv(fileNames[i]+'.csv')\n",
    "        s1 = temp[i].to_numpy()\n",
    "        fig, ax = mt.pyplot.subplots(figsize=(54,15))\n",
    "        columnsName = temp[i].columns.values\n",
    "        rowsName = temp[i].index.values\n",
    "        sd = sns.heatmap(\n",
    "                        s1, cmap='coolwarm', square=True, ax=ax, linewidth='0.5', center=0, vmin= -1*symvalue, vmax=symvalue,\n",
    "                        xticklabels=columnsName, yticklabels=rowsName,  annot=True\n",
    "                )\n",
    "        sd.get_figure().savefig(fileNames[i]+str(symvalue)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans1[1].to_csv('./Controls.csv')\n",
    "\n",
    "columns = temp[1].columns.values\n",
    "\n",
    "rows = temp[1].index.values\n",
    "\n",
    "# print(ans1[0][rows[0]][columns[0]] - ans1[1][rows[0]][columns[0]])\n",
    "\n",
    "for i in rows:\n",
    "    for j in columns:\n",
    "        temp[1].at[i,j] -= temp[0].at[i,j]\n",
    "\n",
    "# ans1[1].to_csv('./difference.csv')\n",
    "\n",
    "st1 = temp[1].to_numpy()\n",
    "\n",
    "fig, ax = mt.pyplot.subplots(figsize=(54,15))\n",
    "\n",
    "sd = sns.heatmap (\n",
    "                st1, \n",
    "                vmin= -1*symvalue, \n",
    "                vmax= symvalue,\n",
    "                cmap='coolwarm', \n",
    "                square=True,\n",
    "                ax=ax,\n",
    "                linewidth='0.5',\n",
    "                center=0, \n",
    "                cbar=True,\n",
    "                xticklabels=columnsName, \n",
    "                yticklabels=rowsName,  \n",
    "                annot=True\n",
    "            )\n",
    "\n",
    "sd.get_figure().savefig('difference'+str(symvalue)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 4d subject\n",
    "    - 53 selected Components\n",
    "        - each component voxel Count - index i\n",
    "\n",
    "AD- 213\n",
    "69  - [ 1_Sub_69Ind_voxelCount, 2_Sub_69Ind_VoxelCount,  ]\n",
    "53  - [ ]\n",
    "\n",
    "1 4D subject:\n",
    "    - preprocess.mat file \n",
    "        - FNC matrix\n",
    "            - Graph metric \n",
    "                - Glo\n",
    "                - Charac\n",
    "                - Coefficint\n",
    "\n",
    "AD- 213\n",
    "Global Efficieny - [ 1_Sub_mat_FNC_Global_Value, 2_Sub_mat_FNC_Global, ..... ]\n",
    "Characterstic Path lenght - [ 1_sub, ........ ]\n",
    "\n",
    "\n",
    "Correlation:\n",
    "Global Efficiency Vs 69 [] - Correlation 0.123\n",
    "Global Efficiency Vs 53 [] - Correlation -0.324\n",
    "                                            0.372\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
