{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bctpy in ./env/lib/python3.6/site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.6/site-packages (from bctpy) (1.19.5)\n",
      "Requirement already satisfied: scipy in ./env/lib/python3.6/site-packages (from bctpy) (1.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # Required Packages for the Project RUN ONLY ONCE\n",
    "# %pip install matplotlib\n",
    "# %pip install nilearn\n",
    "# %pip install openpyxl\n",
    "# %pip install Path\n",
    "# %pip install seaborn\n",
    "# %pip install nltools\n",
    "# %pip install scipy\n",
    "# %pip install scikit-image\n",
    "# %pip install nibabel\n",
    "%pip install bctpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# from skimage import filters\n",
    "# import json\n",
    "# import nibabel as nib\n",
    "# from nilearn.plotting import plot_img\n",
    "\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "from nilearn.image import load_img, index_img\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import networkx as nx\n",
    "import matplotlib as mt\n",
    "import scipy as sc\n",
    "import seaborn as sns\n",
    "import bct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectData:\n",
    "    \n",
    "    def __init__(self, datasetPath, componentsPath):\n",
    "        self.componentFileName = \"adni_aa__sub01_component_ica_s1_.nii\"\n",
    "        self.timeCourseFileName = \"adni_aa__sub01_timecourses_ica_s1_.nii\"\n",
    "        self.FNCmatFile = \"adni_aa__postprocess_results.mat\"\n",
    "        self.component_key = \"fnc_corrs_all\"\n",
    "        self.graphMetricGlobalMeasues = [\n",
    "                # Global Measures\n",
    "                # \"Global efficiency\", \n",
    "                # \"Characteristic path length\", \n",
    "                # \"Clustering coefficient\",\n",
    "            ]\n",
    "        self.graphMetricComponentMeasures = [\n",
    "                # Component Measures\n",
    "                # \"Degree\",\n",
    "                # \"Closeness centrality\",\n",
    "                \"Participation coefficient\"\n",
    "            ]\n",
    "        \n",
    "        self.subjectsData = self.readFileofCSV(datasetPath) \n",
    "        self.componentData = self.readFileofCSV(componentsPath)\n",
    "\n",
    "        self.modifySubjectsPath()\n",
    "\n",
    "        self.domainList = self.componentData[\"icn_domain\"]\n",
    "        self.indexList = self.componentData[\"icn_index\"]\n",
    "\n",
    "    def modifySubjectsPath(self):\n",
    "        for i in range(2404):\n",
    "            self.subjectsData.at[i,\"fc_dir\"] = self.subjectsData.iloc[i][\"fc_dir\"].replace(\"FC\",\"GIGICA\")\n",
    "\n",
    "    def readFileofCSV(self,path):\n",
    "        fileData = pd.read_csv(path)\n",
    "        return fileData\n",
    "    \n",
    "    def getDatasetPaths(self,subjectName):\n",
    "        ans = list()\n",
    "        for i in range(2404):\n",
    "            if self.subjectsData.at[i,\"ResearchGroup\"] == subjectName:\n",
    "                ans.append(self.subjectsData.at[i,\"fc_dir\"])\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelCounts(SubjectData):\n",
    "    \" \\\n",
    "        datasetPath : 4D images path \\\n",
    "        componentsPath: indexes path \\\n",
    "        subjectList: List of subjects to calculate ex: AD, CN, ....  \\\n",
    "    \"\n",
    "    def __init__(self,datasetPath, componentsPath, subjectList):\n",
    "        super().__init__(datasetPath,componentsPath)\n",
    "        self.subjectsToCalculate = subjectList\n",
    "\n",
    "        self.voxelCountMap = dict()\n",
    "        self.prepareVoxelCountMap()\n",
    "\n",
    "    def prepareVoxelCountMap(self):\n",
    "        \" \\\n",
    "            iterate over the list of Subjects like AD, CN, ....     \\\n",
    "        \"\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            self.voxelCountMap[subjectName]=dict()\n",
    "            self.voxelCountMap[subjectName][\"paths\"] = self.getDatasetPaths(subjectName)\n",
    "            self.voxelCountMap[subjectName][\"indexes\"] = dict()\n",
    "            for i in self.indexList:\n",
    "                self.voxelCountMap[subjectName][\"indexes\"][i]=list()\n",
    "\n",
    "    def calculateVoxelCount(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            for path in self.voxelCountMap[subjectName][\"paths\"]:\n",
    "                spacialMapName = path + self.componentFileName\n",
    "                spacialMap = load_img(spacialMapName)\n",
    "                for index in self.voxelCountMap[subjectName][\"indexes\"]:\n",
    "                    actualIndex=index-1\n",
    "                    componentImg = index_img(spacialMap, actualIndex)\n",
    "                    componentImgData = componentImg.get_fdata()\n",
    "                    component_threshold = 3*np.std(componentImgData)\n",
    "                    component_voxelCount = np.count_nonzero(componentImgData > component_threshold)\n",
    "                    self.voxelCountMap[subjectName][\"indexes\"][index].append(component_voxelCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AD_Threshold = VoxelCounts('ADNI_demos.txt', 'NM_icns_info.csv', [\"AD\", \"CN\"])\n",
    "AD_Threshold.calculateVoxelCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMetrics(SubjectData):\n",
    "\n",
    "    \" \\\n",
    "        datasetPath : 4D images path \\\n",
    "        componentsPath: indexes path \\\n",
    "        subjectList: List of subjects to calculate ex: AD, CN, ....  \\\n",
    "    \"\n",
    "\n",
    "    def __init__(self,datasetPath, componentsPath, subjectList):\n",
    "        super().__init__(datasetPath,componentsPath)\n",
    "        self.subjectsToCalculate = subjectList\n",
    "\n",
    "        self.graphMetricMap = dict()\n",
    "        self.prepareGraphMetricMap()\n",
    "\n",
    "    def prepareGraphMetricMap(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            self.graphMetricMap[subjectName]=dict()\n",
    "            self.graphMetricMap[subjectName][\"paths\"] = self.getDatasetPaths(subjectName)\n",
    "            for graphMetric in self.graphMetricGlobalMeasues:\n",
    "                self.graphMetricMap[subjectName][graphMetric]=list()\n",
    "            \n",
    "            for graphMetric in self.graphMetricComponentMeasures:\n",
    "                self.graphMetricMap[subjectName][graphMetric] = dict()\n",
    "                for ind in self.indexList:\n",
    "                    self.graphMetricMap[subjectName][graphMetric][ind]=list()\n",
    "\n",
    "    def loadMatFile(self,filePath):\n",
    "        componentDict = scipy.io.loadmat(filePath+self.FNCmatFile)\n",
    "        return componentDict[self.component_key]\n",
    "\n",
    "    def prepareFNCMatrix(self,componentData):\n",
    "        selected_component = np.zeros((53,53), dtype=np.float64).reshape(53,53)\n",
    "        for i in range(53):\n",
    "            for j in range(i+1, 53):\n",
    "                # if componentData[self.indexList[i]-1][self.indexList[j]-1] >=0 : \n",
    "                selected_component[i][j]=componentData[self.indexList[i]-1][self.indexList[j]-1]\n",
    "        selected_component += selected_component.T\n",
    "\n",
    "        # Finding correlation matrix\n",
    "        corrs = pd.DataFrame(selected_component)\n",
    "        correlation_matrix = corrs.corr()\n",
    "        correlation_numpy_array = correlation_matrix.to_numpy(dtype=np.float64)\n",
    "\n",
    "        # Finding Thresholded correlation matrix\n",
    "        row,column = correlation_numpy_array.shape\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                if i!=j and correlation_numpy_array[i][j]<0:\n",
    "                    correlation_numpy_array[i][j]=0\n",
    "\n",
    "        input_matrix = nx.from_numpy_array(correlation_numpy_array)\n",
    "        return input_matrix\n",
    "\n",
    "    def calculateGraphMetrics(self):\n",
    "        for subjectName in self.subjectsToCalculate:\n",
    "            for path in self.graphMetricMap[subjectName][\"paths\"]:\n",
    "                fncMatrix = self.prepareFNCMatrix(self.loadMatFile(path))\n",
    "\n",
    "                # for global measures:\n",
    "                for graphMetric in self.graphMetricGlobalMeasues:\n",
    "                    if graphMetric == \"Global efficiency\":\n",
    "                        globalEfficieny = nx.global_efficiency(fncMatrix)\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(globalEfficieny)\n",
    "\n",
    "                    elif graphMetric == \"Characteristic path length\":\n",
    "                        characteristicPathLength = nx.average_shortest_path_length(fncMatrix, weight='weight')\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(characteristicPathLength)\n",
    "\n",
    "                    elif graphMetric == \"Clustering coefficient\":\n",
    "                        clusterCofficient = nx.clustering(fncMatrix, weight='weight')\n",
    "                        clusterCofficient_network = 0\n",
    "                        for i in clusterCofficient:\n",
    "                            clusterCofficient_network += clusterCofficient[i]\n",
    "                        clusterCofficient_network /= 53\n",
    "                        self.graphMetricMap[subjectName][graphMetric].append(clusterCofficient_network)\n",
    "\n",
    "                # for component measures\n",
    "                for graphMetric in self.graphMetricComponentMeasures:\n",
    "                    if graphMetric == \"Degree\":\n",
    "                        all_nodes_degree = nx.degree(fncMatrix, weight= 'weight')\n",
    "                        for ind in range(len(self.indexList)):\n",
    "                            self.graphMetricMap[subjectName][graphMetric][self.indexList[ind]].append(all_nodes_degree[ind])\n",
    "                    elif graphMetric == \"Closeness centrality\":\n",
    "                        all_nodes_cc = nx.closeness_centrality(fncMatrix, distance='weight', wf_improved=False)\n",
    "                        for ind in range(len(self.indexList)):\n",
    "                            self.graphMetricMap[subjectName][graphMetric][self.indexList[ind]].append(all_nodes_cc[ind])\n",
    "                    elif graphMetric == \"Participation coefficient\":\n",
    "                        fncMatrix_numpy = nx.to_numpy_array(fncMatrix)\n",
    "                        modularity = nx.algorithms.community.greedy_modularity_communities(fncMatrix)\n",
    "                        sam=[]\n",
    "                        for i in range(len(modularity)):\n",
    "                            for j in list(modularity[i]):\n",
    "                                sam.append(j)\n",
    "                        sam = np.array(sam)\n",
    "                        all_nodes__pc = bct.centrality.participation_coef(fncMatrix_numpy, ci=sam, degree='undirected')\n",
    "                        for ind in range(len(self.indexList)):\n",
    "                            self.graphMetricMap[subjectName][graphMetric][self.indexList[ind]].append(all_nodes_cc[ind])\n",
    "                        break\n",
    "                break\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 36, 5, 6, 7, 46, 15, 48, 27, 28, 44, 41, 51, 52, 21, 1, 2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 45, 47, 49, 50]\n",
      "[0.93656292 0.94143441 0.95154352 0.94907281 0.94899858 0.90801902\n",
      " 0.90776505 0.9219665  0.95379509 0.95441073 0.95403784 0.95461473\n",
      " 0.95788414 0.9591483  0.95630455 0.90610956 0.94894894 0.92552188\n",
      " 0.93960691 0.92850273 0.94401441 0.92932434 0.94760942 0.93740168\n",
      " 0.94867448 0.95971276 0.95637214 0.93449594 0.93171023 0.95085605\n",
      " 0.95784541 0.94764673 0.95565297 0.951718   0.93302607 0.956303\n",
      " 0.89481902 0.95262102 0.95925686 0.951548   0.95432362 0.92160262\n",
      " 0.95068754 0.94568761 0.93358042 0.93615367 0.92097075 0.9605426\n",
      " 0.93119554 0.95243221 0.95084784 0.94138517 0.93003145]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AD_GraphMetric = GraphMetrics('ADNI_demos.txt', 'NM_icns_info.csv', [\"AD\"])\n",
    "AD_GraphMetric.calculateGraphMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphMetrics_Names = AD_GraphMetric.graphMetricNames\n",
    "ans1 = list()\n",
    "\n",
    "for subjectName in AD_GraphMetric.subjectsToCalculate:\n",
    "\n",
    "    table = pd.DataFrame()\n",
    "    for i in range(len(AD_Threshold.indexList)):\n",
    "        table[AD_Threshold.domainList[i]+'('+str(AD_Threshold.indexList[i])+')'] = list()\n",
    "\n",
    "    for i in GraphMetrics_Names:\n",
    "        indexList = AD_Threshold.indexList\n",
    "        corr_list = list()\n",
    "\n",
    "        xlist = AD_GraphMetric.graphMetricMap[subjectName][i]\n",
    "        xmean = np.mean(xlist)\n",
    "        xval = xlist - xmean\n",
    "        xsqu = np.sqrt(np.sum(np.square(xval)))\n",
    "\n",
    "        for j in range(len(indexList)):\n",
    "\n",
    "            ylist = AD_Threshold.voxelCountMap[subjectName][\"indexes\"][AD_Threshold.indexList[j]]\n",
    "            ymean = np.mean(ylist)\n",
    "            yval = ylist - ymean\n",
    "            ysqu = np.sqrt(np.sum(np.square(yval)))\n",
    "\n",
    "            num = 0\n",
    "            for k in range(len(yval)):\n",
    "                num += (xval[k]*yval[k])\n",
    "\n",
    "            den = (xsqu * ysqu)\n",
    "            ans = num/den\n",
    "            corr_list.append(ans)\n",
    "\n",
    "        table.loc[len(table.index)] = corr_list\n",
    "    table.index = AD_GraphMetric.graphMetricNames\n",
    "    ans1.append(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ans1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symvalue = 0.5\n",
    "fileNames = ['Alzhiemeris', 'Controls']\n",
    "for i in range(len(fileNames)):\n",
    "        temp[i].to_csv(fileNames[i]+'.csv')\n",
    "        s1 = temp[i].to_numpy()\n",
    "        fig, ax = mt.pyplot.subplots(figsize=(54,15))\n",
    "        columnsName = temp[i].columns.values\n",
    "        rowsName = temp[i].index.values\n",
    "        sd = sns.heatmap(\n",
    "                        s1, cmap='coolwarm', square=True, ax=ax, linewidth='0.5', center=0, vmin= -1*symvalue, vmax=symvalue,\n",
    "                        xticklabels=columnsName, yticklabels=rowsName,  annot=True\n",
    "                )\n",
    "        sd.get_figure().savefig(fileNames[i]+str(symvalue)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans1[1].to_csv('./Controls.csv')\n",
    "\n",
    "columns = temp[1].columns.values\n",
    "\n",
    "rows = temp[1].index.values\n",
    "\n",
    "# print(ans1[0][rows[0]][columns[0]] - ans1[1][rows[0]][columns[0]])\n",
    "\n",
    "for i in rows:\n",
    "    for j in columns:\n",
    "        temp[1].at[i,j] -= temp[0].at[i,j]\n",
    "\n",
    "# ans1[1].to_csv('./difference.csv')\n",
    "\n",
    "st1 = temp[1].to_numpy()\n",
    "\n",
    "fig, ax = mt.pyplot.subplots(figsize=(54,15))\n",
    "\n",
    "sd = sns.heatmap (\n",
    "                st1, \n",
    "                vmin= -1*symvalue, \n",
    "                vmax= symvalue,\n",
    "                cmap='coolwarm', \n",
    "                square=True,\n",
    "                ax=ax,\n",
    "                linewidth='0.5',\n",
    "                center=0, \n",
    "                cbar=True,\n",
    "                xticklabels=columnsName, \n",
    "                yticklabels=rowsName,  \n",
    "                annot=True\n",
    "            )\n",
    "\n",
    "sd.get_figure().savefig('difference'+str(symvalue)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 4d subject\n",
    "    - 53 selected Components\n",
    "        - each component voxel Count - index i\n",
    "\n",
    "AD- 213\n",
    "69  - [ 1_Sub_69Ind_voxelCount, 2_Sub_69Ind_VoxelCount,  ]\n",
    "53  - [ ]\n",
    "\n",
    "1 4D subject:\n",
    "    - preprocess.mat file \n",
    "        - FNC matrix\n",
    "            - Graph metric \n",
    "                - Glo\n",
    "                - Charac\n",
    "                - Coefficint\n",
    "\n",
    "AD- 213\n",
    "Global Efficieny - [ 1_Sub_mat_FNC_Global_Value, 2_Sub_mat_FNC_Global, ..... ]\n",
    "Characterstic Path lenght - [ 1_sub, ........ ]\n",
    "\n",
    "\n",
    "Correlation:\n",
    "Global Efficiency Vs 69 [] - Correlation 0.123\n",
    "Global Efficiency Vs 53 [] - Correlation -0.324\n",
    "                                            0.372\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
